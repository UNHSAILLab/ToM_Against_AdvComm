{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adir = \"/home/nanci/ray_results/MultiPPO_2021-10-11_10-54-46/MultiPPO_coverage_2d1d6_00000/gaussian/eval_adv-2d1d6-007500_dataset.pkl\"\n",
    "adir = \"/home/nanci/ray_results/MultiPPO_2022-04-12_11-07-33/MultiPPO_coverage_4799f_00000/gaussian/eval_adv-4799f-015000_dataset_with_label.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "dataset = pickle.load(open(adir,'rb'))\n",
    "dataset = dataset[dataset.agent > 0]\n",
    "dataset = np.array([d[0] for d in dataset.dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34500.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[0]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172500, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adir2 = \"/home/nanci/ray_results/MultiPPO_2021-10-11_10-54-46/MultiPPO_coverage_2d1d6_00000/gaussian/dataset_adv.pkl\"\n",
    "\n",
    "adir2 = \"/home/nanci/ray_results/MultiPPO_2022-04-12_11-07-33/MultiPPO_coverage_4799f_00000/gaussian/eval_adv-4799f-015000_dataset_adv_with_label.pkl\"\n",
    "\n",
    "dataset2 = pickle.load(open(adir2,'rb'))\n",
    "dataset2 = dataset2[dataset2.agent == 0]\n",
    "dataset_adv = np.array([d[0] for d in dataset2.dataset]) #np.array(dataset2['dataset'])\n",
    "dataset_adv = dataset_adv.reshape(-1,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_adv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#from vae_net2 import VAE\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import scipy.io\n",
    "import random\n",
    "import math\n",
    "\n",
    "from utils.test import test_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# VAE with one stochastic layer z\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, args, d, h_num, scaled=True):\n",
    "        super(VAE, self).__init__()\n",
    "        self.dim = 128\n",
    "        self.Nz = 10\n",
    "        self.hid_num = h_num\n",
    "        self.output_type = 'gaussian'\n",
    "        self.decoder_type = 'gaussian'\n",
    "        self.scaled_mean = scaled\n",
    "        self.fc1 = nn.Linear(d, h_num)\n",
    "        self.fc2_mu = nn.Linear(h_num, self.Nz)\n",
    "        self.fc2_sigma = nn.Linear(h_num, self.Nz)\n",
    "        self.fc3 = nn.Linear(self.Nz, h_num)\n",
    "        if self.decoder_type == 'gaussian':\n",
    "            self.fc4_mu = nn.Linear(h_num, d)\n",
    "            self.fc4_sigma = nn.Linear(h_num, d)\n",
    "        else:\n",
    "            self.fc4 = nn.Linear(h_num, d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.dim)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        mu_z = self.fc2_mu(x)\n",
    "        log_sigma_z = self.fc2_sigma(x)\n",
    "        eps = torch.randn_like(mu_z)\n",
    "        x = mu_z + torch.exp(log_sigma_z) * eps\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        if self.output_type == 'gaussian':\n",
    "            if self.scaled_mean:\n",
    "                mu = torch.sigmoid(self.fc4_mu(x))\n",
    "            else:\n",
    "                mu = self.fc4_mu(x)\n",
    "            log_sigma = self.fc4_sigma(x)\n",
    "            return mu, mu_z, log_sigma, log_sigma_z\n",
    "        else:\n",
    "            x = self.fc4(x)\n",
    "            return x, mu_z, '_', log_sigma_z\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                                           shuffle=True, num_workers=2)\n",
    "# define the model\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "decoder_type = 'gaussian'\n",
    "\n",
    "batchsize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE( args = None, d=128, h_num=20)\n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adagrad(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if np.isnan(dataset[i]).any():\n",
    "        print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172500/172500 [02:14<00:00, 1284.10it/s, loss=-2.86] \n",
      "  0%|          | 0/172500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: -47.204\n",
      "test average ELBO= 187.78648376464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172500/172500 [02:15<00:00, 1269.50it/s, loss=-5.23]\n",
      "  0%|          | 0/172500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: -325.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172500/172500 [02:21<00:00, 1220.11it/s, loss=-6.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] loss: -503.415\n",
      "Finished Training, time cost 411.60105299949646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    # test\n",
    "    if epoch % 10 == 1:\n",
    "        #print(dataset[:-100].shape)\n",
    "        test_elbo = test_function(net, batchsize, dataset=dataset[:-100], out_type='gaussian',\n",
    "                                  testset=dataset[-100:], device=device)\n",
    "        print('test average ELBO=', test_elbo)\n",
    "\n",
    "    # iterations\n",
    "    running_loss = 0.0\n",
    "    runcnt = 0\n",
    "    with tqdm(total=len(train_loader.dataset)) as progress_bar:\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            train = data.to(device)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = net(train.float())\n",
    "\n",
    "            # the negative KL term\n",
    "            negative_KL = (torch.ones_like(output[1]) + 2 * output[3] - output[1] * output[1] - torch.exp(\n",
    "                2 * output[3])).sum(1) / 2\n",
    "\n",
    "            # the log conditional prob term\n",
    "            if decoder_type == 'gaussian':\n",
    "                train_minus_mu = train - output[0]\n",
    "\n",
    "                log_p_x_given_z = -torch.ones_like(train).sum(1) * np.log(2 * math.pi) / 2 \\\n",
    "                                  - output[2].sum(1) / 2 - (\n",
    "                                          train_minus_mu * train_minus_mu / (2 * torch.exp(output[2]))).sum(1)\n",
    "      \n",
    "            else:\n",
    "                log_p_x_given_z = torch.sum(output[0] * train - torch.log(1 + torch.exp(output[0])), 1)\n",
    "                \n",
    "                \n",
    "            #weights explode so scale it down?\n",
    "            log_p_x_given_z /= data.shape[0] * 128/64\n",
    "\n",
    "            # update parameters\n",
    "            loss = -negative_KL.mean() - log_p_x_given_z.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss -= negative_KL.sum().item()\n",
    "            running_loss -= log_p_x_given_z.sum().item()\n",
    "\n",
    "            # progress bar\n",
    "            progress_bar.set_postfix(loss=loss.mean().item())\n",
    "            progress_bar.update(data.size(0))\n",
    "            runcnt+=1\n",
    "\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / runcnt))\n",
    "\n",
    "print('Finished Training, time cost', time.time() - start)\n",
    "\n",
    "PATH = 'save/vae_' + '_dataset_'  + '_decoder_' + 'readapt_coop.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.9554069 ,  2.5773318 ,  0.        ,  6.871078  ,\n",
       "       11.239436  ,  3.9592528 ,  4.0226893 ,  0.        ,  0.        ,\n",
       "        2.7727277 ,  0.        ,  0.        ,  0.        ,  4.02565   ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.8181938 ,\n",
       "        3.8436553 ,  0.        ,  0.        ,  4.386832  ,  0.        ,\n",
       "        5.0052257 ,  0.27447602,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, mu_z, log_sigma, log_sigma_z = net.forward(torch.Tensor(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9239e-01, 9.9826e-01, 2.9605e-01, 6.1260e-01, 9.9433e-01, 9.9565e-01,\n",
       "         9.9570e-01, 9.9426e-01, 9.9809e-01, 9.9614e-01, 9.9490e-01, 9.4750e-01,\n",
       "         9.9307e-01, 1.3457e-01, 9.7747e-01, 9.9242e-01, 9.9795e-01, 9.9349e-01,\n",
       "         9.9296e-01, 5.2316e-01, 9.8977e-01, 9.9513e-01, 2.8743e-01, 7.9217e-01,\n",
       "         9.9068e-01, 9.8050e-01, 9.9605e-01, 3.7802e-01, 9.8746e-01, 2.9398e-02,\n",
       "         9.9301e-01, 4.1219e-01, 8.6880e-09, 7.9743e-09, 6.8640e-09, 7.1773e-09,\n",
       "         8.5179e-09, 7.5585e-09, 4.2870e-09, 6.2457e-09, 1.0953e-08, 6.7820e-09,\n",
       "         6.3545e-09, 6.8628e-09, 1.0098e-08, 6.8005e-09, 6.9060e-09, 1.2164e-08,\n",
       "         8.1040e-09, 6.7816e-09, 6.9111e-09, 1.1230e-08, 6.9401e-09, 8.0183e-09,\n",
       "         1.0905e-08, 4.9857e-09, 6.0034e-09, 7.4084e-09, 6.6933e-09, 1.0392e-08,\n",
       "         7.9350e-09, 5.3685e-09, 8.2102e-09, 5.9740e-09, 1.2416e-08, 6.6210e-09,\n",
       "         9.2343e-09, 7.4735e-09, 1.1644e-08, 9.1943e-09, 8.8573e-09, 7.1090e-09,\n",
       "         7.2539e-09, 8.7484e-09, 6.7874e-09, 5.8110e-09, 8.9399e-09, 8.3577e-09,\n",
       "         7.2549e-09, 9.7602e-09, 8.4451e-09, 8.6856e-09, 5.8794e-09, 9.0814e-09,\n",
       "         4.5313e-09, 9.0421e-09, 6.6744e-09, 7.1819e-09, 3.8457e-09, 8.6804e-09,\n",
       "         6.7088e-09, 7.2783e-09, 1.1066e-08, 1.2649e-08, 7.3332e-09, 7.1845e-09,\n",
       "         7.5918e-09, 5.8134e-09, 5.8614e-09, 6.3580e-09, 7.6730e-09, 6.1959e-09,\n",
       "         8.8344e-09, 1.1270e-08, 6.0923e-09, 5.1861e-09, 7.6928e-09, 1.1157e-08,\n",
       "         7.1270e-09, 7.2508e-09, 6.9291e-09, 8.7411e-09, 6.5382e-09, 1.0644e-08,\n",
       "         5.5527e-09, 1.1088e-08, 7.4731e-09, 9.7382e-09, 7.2780e-09, 6.6077e-09,\n",
       "         1.1267e-08, 7.6908e-09, 9.4790e-09, 6.3461e-09, 6.2128e-09, 1.1527e-08,\n",
       "         5.2775e-09, 8.9400e-09]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
