{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Theory-of-Mind Mitigation Against Adversarial Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies:\n",
    "- Python 3.7.11\n",
    "- Raylib 1.3.0\n",
    "- [Adversarial Comm](https://github.com/proroklab/adversarial_comms) Repository\n",
    "- [Auto Encoding Variational Bayes](https://github.com/angzhifan/Auto-Encoding_Variational_Bayes) Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the original [Adversarial Comms](https://github.com/proroklab/adversarial_comms) Github Pepository from Proroklab.\n",
    "\n",
    "1. From your terminal, run `git pull https://github.com/proroklab/adversarial_comms.git`\n",
    "2. Either follow the repo's installation instructions or continue to (3)\n",
    "3. Run `pip install -r requirements.txt'\n",
    "4. Run `python setup.py install`\n",
    "5. We modified `CoverageEnv`'s configuration file, so adjust accordingly to available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in the Standard Coverage Environment\n",
    "1. Follow the directions from the adv_comm repo or continue to (2).\n",
    "2. Run `python train_policy.py coverage -t 6` to train the cooperative team in the coverage environment for 6 million timesteps with only cooperative agents.\n",
    "3. Run `python continue_policy.py [cooperative checkpoint path] -t 12 -e coverage -o self_interested` to train the self-interested agent for 6 million timesteps given a fixed cooperative policy.\n",
    "4. Run `python continue_policy.py [adversarial checkpoint path] -t 18 -e coverage -o re_adapt` to have the cooperative team retrain/perform readaption training in the presence of a fixed adversary policy.\n",
    "5. Please note the location of where the model parameters are saved, they will be needed for the checkpoint variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the Dataset for the VAEB Defense\n",
    "1. Open `Generate_Coop_Team_Dataset.py` and replace the directories of where the datasets will be saved and which cooperative model to load in. Then run `python Generate_Coop_Team_Dataset.py`. The cooperative team dataset ends with `_dataset_with_label.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull a Variational [Auto-Encoder Bayes](https://github.com/angzhifan/Auto-Encoding_Variational_Bayes) Github Repository for some utilities.\n",
    "1. Run `git pull https://github.com/angzhifan/Auto-Encoding_Variational_Bayes`. We leverage some helper functions from the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the VAEB model using the dataset collected from the Cooperative Team\n",
    "1. Open `VAEB_Training.ipynb` and replace all directories with directories pointing to your cooperative team's dataset. Replace the VAEB output path-name e.g. `/vae/vaeb_from_coop_dataset.pth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Search for Variable Rho\n",
    "1. Run `python ParameterSearchingRho.py` will evaluate our theory of mind mitigation method with various intervals for the parameter rho. We selected rho based on an analysis plot of return over episodes per fixed interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Baseline and Defenses.\n",
    "\n",
    "1. Open `Evaluate_VAEB.py` and replace the <b> cooperative team model</b> directory and <b> VAEB model</b> directory with yours. Run `python Evaluate_VAEB.py` which will generated the <b> VAEB baseline for the cooperative team performance before readaption in CoverageEnv </b>.\n",
    "2. Open `Evaluate_VAEB.py` and replace the <b> readapted cooperative team model directory</b> and <b> VAEB model</b> directory with yours. Run `python Evaluate_VAEB.py` which will generated the <b> VAEB performance for the readapted cooperative team in CoverageEnv </b>.\n",
    "3. Open `ParameterSearchingRho.py` and comment-in `eval_nocomm_adv(mode=0)` and comment-out the line above it `eval_nocomm_adv(mode=1)`. Replace the <b> cooperative team before readaption directory</b> with yours and the <b> evaluation output directory</b> where you would like to store the evaluation scores. This will generated the ToM defense performance for the cooperative team before readaption training.\n",
    "3. Open `ParameterSearchingRho.py` and comment-in `eval_nocomm_adv(mode=0)` and comment-out the line above it `eval_nocomm_adv(mode=1)`. Replace the <b> readapted cooperative team directory</b> with yours and the <b> readaption evaluation output directory</b> where you would like to store the evaluation scores. This will generated the ToM defense performance for the readapted cooperative team.\n",
    "4. To generate the performance baselines: <b> no defense cooperative performance, no adversary communication cooperative performance, ideal cooperative performance, adversary performance with no communication, and adversary performance with no cooperative team defense </b> from the adversarial comm repo, following their evaluation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the Evaluations and Aggregations\n",
    "1. Open `PerformanceComparison.ipynb` and replace your evaluation directories for the cooperative team before readaption training for ToM, VAEB and other baselines mentioned in section prior. The first generated graph is the performance comparison prior to readaption training.\n",
    "2. Open `PerformanceComparison.ipynb` and replace your evaluation directories for the readapted cooperative team before for ToM, VAEB and other baselines mentioned in section prior. The second generated graph is the performance comparison of the defenses given readapted cooperative team.\n",
    "3. Open `PerformanceComparison.ipynb` and replace the evaluation directories to generate the F1-score, False Positive, False Negative, True Positive and True Negative plot analysis of the ToM defense in comparison to the VAEB.\n",
    "\n",
    "\n",
    "\n",
    "<p float=\"left\">\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "<div style=\"display:flex\">\n",
    "     <div style=\"flex:1;padding-right:0px;\">\n",
    "            <img src=\"./out_2.png\" width=\"100%\" />\n",
    "     </div>\n",
    "     <div style=\"flex:1;padding-left:0px;\">\n",
    "            <img src=\"./out_readapt.png\" width=\"100%\" />\n",
    "     </div>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
